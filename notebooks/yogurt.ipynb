{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>üç∂ <b style=\"color: lightblue\">\"Churning\"</b> the data üç∂</h1>\n",
    "    <h3>An exploratory data analysis of yogurt brand <s>Twi...</s> <b style=\"font-size: 2rem; color: lightblue;\">ùïè</b></h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b><span style=\"color:#0074D9\">Main Objective:</span></b> to give a detailed data analysis of data acquired from ùïè in order to equip our client with actionable, evidence-based insights.\n",
    "  - Provide a clean dataset, separated by company type\n",
    "  - Garner tweet <i>(or xeet or whatever they're called now)</i> sentiment using a pretrained model from huggingfaceü§ó\n",
    "  - Classify tweets into complaints that could be potentially detrimental to the brand.\n",
    "  - Report on the broad themes discovered from our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by importing our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the root of your project is in sys.path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.processing.preprocess import *\n",
    "from src.resources.brands_data import Brand, brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Step 1: Clean the data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation: 3 CSVs ‚û° 1 DataFrame\n",
    "\n",
    "We started our analysis by combining the separate raw csv files into a single dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = get_csv_files()\n",
    "print(f\"Number of csv files ::: {len(csv_list)}\")\n",
    "combined_data_frame = combine_csv_data(csv_list)\n",
    "# remove twitter links - regex test here https://regex101.com/r/wZ0dAP/1\n",
    "combined_data_frame[\"text\"] = combined_data_frame[\"text\"].str.replace(\n",
    "    r\"http[s]?://t\\.[^\\s]*|[^[$]]\", \"\", regex=True\n",
    ")\n",
    "print(f\"Combined data frame length ::: {len(combined_data_frame)}\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "display(combined_data_frame.iloc[10000:].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Orgnization: Creation of a `Brand` Class\n",
    "\n",
    "<div style=\"display: flex; justify-items: stretch;\">\n",
    "    <div>\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Brand:\n",
    "    \"\"\"\n",
    "    Brand object\n",
    "    \"\"\"\n",
    "    twitter_handles: List[str]\n",
    "    brand_name: str\n",
    "    alternate_names: List[str] = field(default_factory=list)\n",
    "    negative_keywords: List[str] = field(default_factory=list)\n",
    "    is_nonspecific_name: bool = False\n",
    "    has_food_related_name: bool = False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div style=\"justify-self: start;\">\n",
    "\n",
    "#### Example Brand:\n",
    "\n",
    "```python\n",
    "\"Activia\": Brand(\n",
    "    twitter_handles=[\n",
    "        \"@activia\",\n",
    "        \"@activiauk\",\n",
    "    ],\n",
    "    brand_name=\"Activia\",\n",
    "    negative_keywords=[\n",
    "        \"activia benz\",\n",
    "        \"mens-rights-activia\",\n",
    "    ],\n",
    "),\n",
    "```\n",
    "\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "We structured our brand data using a dataclass called `Brand` which helps us:\n",
    "\n",
    "- <b><span style=\"color:#0074D9\">Categorize Brands:</span></b> Using Twitter handles and brand names.\n",
    "- <b><span style=\"color:#0074D9\">Handle Ambiguities:</span></b> Some brand names might be similar to everyday words. Including alternative names can help us capture tweets from different regions and even help to catch common mispellings.\n",
    "- <b><span style=\"color:#0074D9\">Filter Out Noise:</span></b> Using negative keywords, we can eliminate irrelevant tweets, ensuring our insights are grounded in relevant data.\n",
    "- <b><span style=\"color:#0074D9\">Address Special Cases:</span></b> Some brands might have non-specific names (e.g. - a brand name closely associated with food)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing:\n",
    "\n",
    "<h4 style=\"color: green\">We will show the journey of a single company's data: <code>\"Greek Gods\"</code> from raw data into processed data.</h4>\n",
    "\n",
    "<div>We took several steps in cleansing the data:</div>\n",
    "\n",
    "1. <b><span style=\"color:#0074D9\">Determined Company List:</span></b> Given the unique names under the `file` column, we were left with [the following companies.](../notes/companies_list.txt)\n",
    "    * We <span style=\"color:crimson\">removed</span> <i>Vanilla Bean</i> as it appeared to not be a valid company.  Keeping it also muddied the analysis process due to its association with food.\n",
    "3. <b><span style=\"color:#0074D9\">Filtered Dataset:</span></b> We used several criteria to do this:\n",
    "    * <u>[Word Association Lists](../src/resources/word_lists.py)</u> - given to brands based on their \"uniqueness\"\n",
    "        * A brand like `Chobani` can be categorized as more unique than `Libert√©` given its French origin.\n",
    "        * `Greek Gods` is an example of a non-specific company name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. <b><span style=\"color: #0074D9\">Removing negative keywords:</span></b> Removed common instances that need specific filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\nBefore filtering ::: {len(combined_data_frame)} items.\")\n",
    "\n",
    "remove_tweets_with_negative_keywords(combined_data_frame, brands[\"Fage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <b><span style=\"color:#0074D9\">Handle Ambiguities:</span></b> Some brand names might be similar to everyday words. Including alternative names can help us capture tweets from different regions and even help to catch common mispellings.\n",
    "3. <b><span style=\"color:#0074D9\">Filter Out Noise:</span></b> Using negative keywords, we can eliminate irrelevant tweets, ensuring our insights are grounded in relevant data.\n",
    "4. <b><span style=\"color:#0074D9\">Address Special Cases:</span></b> Some brands might have non-specific names (e.g. - a brand name closely associated with food)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
