{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <h1>üç∂ <b style=\"color: lightblue\">\"Churning\"</b> the data üç∂</h1>\n",
    "    <h3>An exploratory data analysis of yogurt brands <s>Twi...</s> <span style=\"color: cornflowerblue;\">ùïè</span>.com</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- <b><span style=\"color:#0074D9\">Main Objective:</span></b> to give a detailed data analysis of data acquired from ùïè in order to equip our client with actionable, evidence-based insights.\n",
    "  - Provide a clean dataset, separated by company type\n",
    "  - Garner tweet <i>(or xeet or whatever they're called now)</i> sentiment using a pretrained model from huggingfaceü§ó\n",
    "  - Classify tweets into complaints that could be potentially detrimental to the brand.\n",
    "  - Report on the broad themes discovered from our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's start by importing our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import all dependencies\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "os.chdir('..')\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "from src.processing.preprocess import *\n",
    "from src.resources.brands_data import Brand, brands\n",
    "from src.resources.word_lists import *\n",
    "from src.processing.sentiment_analysis import analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Step 0: Setup the environment`\n",
    "\n",
    "1. Set up project using conda\n",
    "2. Set up tiered, multi-environment approach utilizing either CUDA or MPS (Metal Performance Shaders) based on OS environment\n",
    "    ```python\n",
    "    # Check if MPS is available\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal GPU) device.\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA device.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU device.\")\n",
    "    ```\n",
    "3. Chose dependencies\n",
    "    * [Twitter-roBERTa-base](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) for Sentiment Analysis\n",
    "    * [NLTK](https://www.nltk.org/) for tokenization and frequency analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Step 1: Clean the data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Data Preparation: 3 CSVs ‚û° 1 DataFrame\n",
    "\n",
    "* We started our analysis by combining the separate raw csv files into a single dataframe and removing any twitter links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# preprocessing.preprocess_data()\n",
    "csv_list = get_csv_files()\n",
    "\n",
    "combined_data_frame = combine_csv_data(csv_list)\n",
    "\n",
    "# remove twitter links - regex test here https://regex101.com/r/wZ0dAP/1\n",
    "combined_data_frame[\"text\"] = combined_data_frame[\"text\"].str.replace(\n",
    "    r\"http[s]?://t\\.[^\\s]*|[^[$]]\", \"\", regex=True\n",
    ")\n",
    "\n",
    "### Display datatable ###\n",
    "print(f\"Number of csv files ::: {len(csv_list)}\")\n",
    "print(f\"Combined data frame length ::: {len(combined_data_frame)} rows\")\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "display(combined_data_frame.iloc[10000:].head(3))\n",
    "### for display purposes ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Orgnization: Creation of a `Brand` Class\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between\">\n",
    "    <div style=\"margin: 2%\">\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Brand:\n",
    "    \"\"\"\n",
    "    Brand object\n",
    "    \"\"\"\n",
    "    twitter_handles: List[str]\n",
    "    brand_name: str\n",
    "    alternate_names: List[str] = field(default_factory=list)\n",
    "    negative_keywords: List[str] = field(default_factory=list)\n",
    "    is_nonspecific_name: bool = False\n",
    "    has_food_related_name: bool = False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div style=\"margin-left: 3%; margin-right: 3%;\">\n",
    "\n",
    "#### Example Brand:\n",
    "\n",
    "```python\n",
    "\"Activia\": Brand(\n",
    "    twitter_handles=[\n",
    "        \"@activia\",\n",
    "        \"@activiauk\",\n",
    "    ],\n",
    "    brand_name=\"Activia\",\n",
    "    negative_keywords=[\n",
    "        \"activia benz\",\n",
    "        \"mens-rights-activia\",\n",
    "    ],\n",
    "),\n",
    "```\n",
    "\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "We structured our brand data using a dataclass called `Brand` which helps us:\n",
    "\n",
    "- <b><span style=\"color:#0074D9\">Categorize Brands:</span></b> Using Twitter handles and brand names.\n",
    "- <b><span style=\"color:#0074D9\">Handle Ambiguities:</span></b> Some brand names might be similar to everyday words. Including alternative names can help us capture tweets from different regions and even help to catch common mispellings.\n",
    "- <b><span style=\"color:#0074D9\">Filter Out Noise:</span></b> Using negative keywords, we can eliminate irrelevant tweets, ensuring our insights are grounded in relevant data.\n",
    "- <b><span style=\"color:#0074D9\">Address Special Cases:</span></b> Some brands might have non-specific names (e.g. - a brand name closely associated with food)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Cleansing:\n",
    "\n",
    "<h4 style=\"color: green\">We will show the journey of a single company's data: <code>\"Greek Gods\"</code> from raw data into processed data.</h4>\n",
    "\n",
    "<div>We took several steps in cleansing the data:</div>\n",
    "\n",
    "1. <b><span style=\"color:#0074D9\">Created Company List:</span></b> Given the unique names under the `file` column, we were left with [the following companies.](../notes/companies_list.txt)\n",
    "    * We <span style=\"color:crimson\">removed</span> <i>Vanilla Bean</i> as it appeared to not be a valid company.  Keeping it also muddied the analysis process due to its association with food.\n",
    "    <br><br>\n",
    "2. <b><span style=\"color:#0074D9\">Filtered Dataset:</span></b> We used several criteria to do this:\n",
    "    * <u>[Word Association Lists](../src/resources/word_lists.py)</u> - given to brands based on their \"uniqueness\"\n",
    "        * A brand like <span style=\"color: goldenrod\">Chobani</span> can be categorized as more unique than <span style=\"color: goldenrod\">Libert√©`</span> given its French origin.\n",
    "        * <span style=\"color: goldenrod\">Greek Gods</span> is an example of a non-specific company name\n",
    "    * <u>Removing Negative Keywords</u> - Limited keywords that are known exceptions\n",
    "        * e.g. - A proper name like <span style=\"color: goldenrod\">Activia Jones</span> against a normally sufficiently unique <span style=\"color: goldenrod\">Activia</span> brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess.prepare_data_for_filtering()\n",
    "brand = \"Greek Gods\"\n",
    "\n",
    "if brands[brand]:\n",
    "    filtered_data_frame = filter_irrelevant_data(combined_data_frame, brand=brands[brand], relevancy_threshold=0)\n",
    "    filtered_data_frame = remove_tweets_with_negative_keywords(filtered_data_frame, brands[brand])\n",
    "\n",
    "    pd.set_option(\"display.max_columns\", 10)\n",
    "    pd.set_option(\"display.max_colwidth\", 100)\n",
    "    display(filtered_data_frame.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We did not dedupe data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(\n",
    "    data_frame=filtered_data_frame,\n",
    "    company_name=brand.lower().replace(\" \", \"_\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\nBefore filtering ::: {len(combined_data_frame)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Potential Improvements`\n",
    "* Use NER (Named Entity Recognition) for getting yogurt and company related keywords\n",
    "* Utilize NTLK for initial data filtering"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "rise": {
   "auto_select": "code",
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "night"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
